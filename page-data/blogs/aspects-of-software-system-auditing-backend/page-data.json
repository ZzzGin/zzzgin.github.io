{
    "componentChunkName": "component---src-templates-md-template-js",
    "path": "/blogs/aspects-of-software-system-auditing-backend",
    "result": {"data":{"markdownRemark":{"html":"<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#overall\">Overall</a></li>\n<li><a href=\"#security\">Security</a></li>\n<li><a href=\"#architecture\">Architecture</a></li>\n<li><a href=\"#monitoring\">Monitoring</a></li>\n<li><a href=\"#dependencies\">Dependencies</a></li>\n<li><a href=\"#infrastructure\">Infrastructure</a></li>\n<li><a href=\"#scaling\">Scaling</a></li>\n<li><a href=\"#dynamodb\">DynamoDB</a></li>\n<li><a href=\"#relational-database\">Relational Database</a></li>\n<li><a href=\"#lambda\">Lambda</a></li>\n<li><a href=\"#kinesis\">Kinesis</a></li>\n<li><a href=\"#elasticsearch\">ElasticSearch</a></li>\n<li><a href=\"#api-gateway\">API Gateway</a></li>\n<li><a href=\"#swf\">SWF</a></li>\n<li><a href=\"#sqs\">SQS</a></li>\n<li><a href=\"#ecs\">ECS</a></li>\n</ul>\n</div>\n<h2 id=\"overall\" style=\"position:relative;\"><a href=\"#overall\" aria-label=\"overall permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Overall</h2>\n<ul>\n<li>Describe the software's architecture - architecture diagram?</li>\n<li>Describe the software's use cases?</li>\n<li>Mechanisms to reduce blast radius\n<ul>\n<li>network: environments separation - podding, soak deployment - onebox</li>\n<li>bad deployment: testings - unit tests, integration tests, E2E tests</li>\n</ul>\n</li>\n<li>Think about the conditions which could cause catastrophes, list the cuases and how long it would take to reach the point of totally failure. Ex:\n<ul>\n<li>High dependency API latency causing excessive timeouts</li>\n<li>degenerated client call patterns</li>\n<li>loss of caching solution</li>\n</ul>\n</li>\n<li>List all changes recently could impact scaling, performance, dependencies or clients</li>\n<li>SOPs runbook, datarecovery mechanism in place?</li>\n</ul>\n<h2 id=\"security\" style=\"position:relative;\"><a href=\"#security\" aria-label=\"security permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Security</h2>\n<ul>\n<li>Is data processed by this service confidential? If yes, how is security maintained in this service?</li>\n<li>Do certificates have a renew policy?</li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<ul>\n<li>What is the \"Unit of work\"?\n<ul>\n<li>What is the basic factor of the traffic of the software</li>\n</ul>\n</li>\n<li>What is the AZ redundancy?\n<ul>\n<li>AZ - Available Zone, a term used in AWS. AZ contains hosts. Hosts in different AZ are in different data center. Catastrophe (for example power loss) happens in one AZ will NOT impact other AZs.</li>\n<li>AZ redundency - the software can withstand at least one AZ loss.</li>\n<li>Homogeneous is required amoung all AZs</li>\n</ul>\n</li>\n<li>Any <strong>throttling</strong> techniques?\n<ul>\n<li>How long it will take to change the throttling config?</li>\n</ul>\n</li>\n<li>Health Check\n<ul>\n<li>Ping check</li>\n<li>Carnaval test</li>\n</ul>\n</li>\n<li>List down top clients. Alarms, SOPs.</li>\n</ul>\n<h2 id=\"monitoring\" style=\"position:relative;\"><a href=\"#monitoring\" aria-label=\"monitoring permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitoring</h2>\n<ul>\n<li>Monitors are recommended to use percentage instead of count</li>\n<li>Is the deployment connected to auto-rollback monitors?</li>\n</ul>\n<h2 id=\"dependencies\" style=\"position:relative;\"><a href=\"#dependencies\" aria-label=\"dependencies permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dependencies</h2>\n<ul>\n<li>For data store in the software, any recovery mechanisms in place to recover from lost or corrupted data?\n<ul>\n<li>Is there a \"runbook\"?</li>\n<li>Is it in theory? Have we tried that in practice?</li>\n<li>How long it will take to execute the recovery mechanism?</li>\n</ul>\n</li>\n<li>The <strong>timeout</strong> of API should be larger than the sum of timeout of all dependencies get called in this API</li>\n<li>Impacts when dependency becomes unavailable for certain timerange(5 mins, 30 mins, 3 hours, 1 day)</li>\n<li>Are your dependencies are able to handle the load from this software?</li>\n<li>Do we have dependency alarms? - Latency, timeout, throttling, Faults, Errors...</li>\n<li>SOP of engaging these service dependencies</li>\n<li>Is extra time required to \"cold restart\" the software?</li>\n<li>Is there dependency causing reoccuring issue</li>\n<li>For retrying on dependencies, is there mechanism to stop unnecessary retries? Any possibilities causing \"retry strom\"?</li>\n</ul>\n<h2 id=\"infrastructure\" style=\"position:relative;\"><a href=\"#infrastructure\" aria-label=\"infrastructure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Infrastructure</h2>\n<ul>\n<li>Alarms on service architecture - CPU, Disk Utilization, Database latencies</li>\n<li>Is logging managed to reduce the risk on having issue with disk useage?\n<ul>\n<li>Logger rate limiting: BurstFilter in Log4j</li>\n<li>Disk Space Log Filter: discard log events when free disk space drops below some threshold</li>\n<li>Automatic log cleaning mechanism</li>\n<li>Discard Policy</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"scaling\" style=\"position:relative;\"><a href=\"#scaling\" aria-label=\"scaling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scaling</h2>\n<ul>\n<li>Chaos testing: load testing against the service with fault-injection framework.\n<ul>\n<li>hijack the dependency call and create some timeout</li>\n<li>increase the latency</li>\n<li>CPU hog test</li>\n<li>MEM hog test</li>\n</ul>\n</li>\n<li>Any ACL (Access Control List)? Any whitelist/blacklist and what is the effort to change them?</li>\n<li>What is the network of this service? Internet? Or private network? Any special steps for cold start on new hosts in this network?</li>\n<li>Load Test result\n<ul>\n<li>CPU</li>\n<li>MEM</li>\n<li>DISK</li>\n<li>Latency</li>\n<li>ERROR/Failure Rate</li>\n<li>Outstanding request (how many threads are running simultaneously on the same hosts? )</li>\n</ul>\n</li>\n<li>Based on the reasult, what is the bottleneck?</li>\n<li>Scaling factor - 2x? 5x? Why?</li>\n</ul>\n<h2 id=\"dynamodb\" style=\"position:relative;\"><a href=\"#dynamodb\" aria-label=\"dynamodb permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DynamoDB</h2>\n<ul>\n<li>How did you determine your service RCU/WCU needs</li>\n<li>Have you verified that your GSIs are correctly scaled to handle Read and Write traffic? (Note that if a GSI runs out of WCUs it will throttle writes to the main table. For each table, if you are using a GSI how have you allocated sufficient WCUs to take this into account?)</li>\n<li>What are the per table and per account limits of your DynamoDB account?</li>\n<li>Did you review the DDB tables and their capacity modes (On-Demand or Provisioned)?</li>\n</ul>\n<h2 id=\"relational-database\" style=\"position:relative;\"><a href=\"#relational-database\" aria-label=\"relational database permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Relational Database</h2>\n<ul>\n<li>Is an RDBMS your primary data source for this Service? Which provider is it (Oracle, MySQL, Postgres, RDS, etc)?</li>\n<li>Have you engaged the DBA's to review your RDBMS peak requirements?</li>\n<li>If your service uses pods, have you confirmed that your DB can handle the total connections from each POD?</li>\n</ul>\n<h2 id=\"lambda\" style=\"position:relative;\"><a href=\"#lambda\" aria-label=\"lambda permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lambda</h2>\n<ul>\n<li>If using DDB/S3 as triggers, did you test with different batch and record sizes? This will help in increasing the throughput. Ref: <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html#stream-events\">https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html#stream-events</a></li>\n<li>If you are using provisioned concurrency, did you verify that will not brown out unpublished version of the function?Note: Provisioned concurrency counts towards a function's reserved concurrency and Regional limits. If the amount of provisioned concurrency on a function's versions and aliases adds up to the function's reserved concurrency, all invocations run on provisioned concurrency. This configuration also has the effect of throttling the unpublished version of the function ($LATEST), which prevents it from executing.</li>\n<li>What is the deployment package size of your Lambda function? You can find this from your AWS console. Limit ref: <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html\">https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html</a></li>\n</ul>\n<h2 id=\"kinesis\" style=\"position:relative;\"><a href=\"#kinesis\" aria-label=\"kinesis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kinesis</h2>\n<ul>\n<li>While scaling a service that utilizes Kinesis, do you have monitors, metrics, and alarms in place in line with the Kinesis best practices?\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/streams/latest/dev/introduction.html\">https://docs.aws.amazon.com/streams/latest/dev/introduction.html</a></li>\n<li><a href=\"https://docs.aws.amazon.com/streams/latest/dev/disaster-recovery-resiliency.html\">https://docs.aws.amazon.com/streams/latest/dev/disaster-recovery-resiliency.html</a></li>\n</ul>\n</li>\n<li>Did you load test your Kinesis consumer? <a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html\">https://docs.aws.amazon.com/streams/latest/dev/kinesis-record-processor-scaling.html</a></li>\n<li>Do you use Kinesis Client Library (KCL) or Kinesis Producer Library (KPL)?</li>\n<li>Did you verify the provisioned throughput capacity of your DynamoDB table? For each KCL/KPL application, a unique Amazon DynamoDB table is used to keep track of the application's state. If your application receives provisioned-throughput exceptions,it might be because of the insufficient provisioned throughput of the table.\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/streams/latest/dev/introduction.html\">https://docs.aws.amazon.com/streams/latest/dev/introduction.html</a></li>\n<li><a href=\"https://docs.aws.amazon.com/cli/latest/reference/dynamodb/describe-table.html\">https://docs.aws.amazon.com/cli/latest/reference/dynamodb/describe-table.html</a></li>\n</ul>\n</li>\n<li>Do you have an sufficient rentention period set for your streams? The default retention period for an AWS Kinesis stream is 24 hours. To ensure that your consumers are able to read stream data before it expires if any problems occur, you can extend your data retention period up to 168 hours (7 days).\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-extended-retention.html\">https://docs.aws.amazon.com/streams/latest/dev/kinesis-extended-retention.html</a></li>\n</ul>\n</li>\n<li>Do you have the recommended alarms configured for Amazon Kinesis Data Streams\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/streams/latest/dev/monitoring.html\">https://docs.aws.amazon.com/streams/latest/dev/monitoring.html</a></li>\n<li><a href=\"https://docs.aws.amazon.com/streams/latest/dev/monitoring-with-cloudwatch.html\">https://docs.aws.amazon.com/streams/latest/dev/monitoring-with-cloudwatch.html</a></li>\n</ul>\n</li>\n<li>Did you override the polling frequency by changing idleTimeBetweenReadsInMillis? If so, how did you verify that this is the ideal value? If this value is set improperly, there can be and increase in exceptions and latency.\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/streams/latest/dev/kinesis-low-latency.html\">https://docs.aws.amazon.com/streams/latest/dev/kinesis-low-latency.html</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"elasticsearch\" style=\"position:relative;\"><a href=\"#elasticsearch\" aria-label=\"elasticsearch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ElasticSearch</h2>\n<ul>\n<li>Load testing</li>\n<li>Are you deploying the domain across three Availability Zones. This configuration lets Amazon ES distribute replica shards to different Availability Zones than their corresponding primary shards. For a list of regions that have three Availability Zones and some other considerations, see <a href=\"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/what-is.html\">Configuring a Multi-AZ Domain</a></li>\n</ul>\n<h2 id=\"api-gateway\" style=\"position:relative;\"><a href=\"#api-gateway\" aria-label=\"api gateway permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>API Gateway</h2>\n<ul>\n<li>Have you reviewed your APIGateway API-level throttling limits for peak, and ensured they are adequate to meet your scaling factor for peak traffic?\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html\">https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-request-throttling.html</a></li>\n</ul>\n</li>\n<li>If the service employs a usage plan for per client and per-client-per-method throttling, please list the rate, burst limit and quota for each rule.</li>\n<li>If your API Gateway cache is enabled, list the cache size and TTL for each API and stage. Also list how you determined that this is the appropriate cache size/TTL. If not enabled, please explain why.\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html\">https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-caching.html</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"swf\" style=\"position:relative;\"><a href=\"#swf\" aria-label=\"swf permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SWF</h2>\n<ul>\n<li>Do you have alarms in place to monitor the number of calls to SWF to handle throttling issues?</li>\n<li>Is your maximum execution history size more than 10k events? The best practice is to structure each workflow such that its history does not grow beyond 10,000 events. The decider has to fetch the workflow history, so a smaller history allows the decider to complete more quickly.\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-dg-limits.html#swf-dg-limits-workflow-executions\">https://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-dg-limits.html#swf-dg-limits-workflow-executions</a></li>\n<li><a href=\"https://docs.aws.amazon.com/cli/latest/reference/swf/get-workflow-execution-history.html\">https://docs.aws.amazon.com/cli/latest/reference/swf/get-workflow-execution-history.html</a></li>\n</ul>\n</li>\n<li>What is the maximum number of pollers your service utilizes per task list? The maximum is 1,000 - but you can encounter LimitExceededException errors well before this quota. To reduce these errors, use multiple task lists to distribute polling.\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-dg-limits.html\">https://docs.aws.amazon.com/amazonswf/latest/developerguide/swf-dg-limits.html</a></li>\n</ul>\n</li>\n<li>Do you have metrics and alarms configured to check if your activity and decider workers are healthy?</li>\n<li>Are you using workflow methods to perform long-running tasks? It is not recommended to do so. Replay can repeat that task multiple times, and even asynchronous workflow methods typically run more than once. Instead, use activities for long running tasks; replay executes activities only once.</li>\n</ul>\n<h2 id=\"sqs\" style=\"position:relative;\"><a href=\"#sqs\" aria-label=\"sqs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SQS</h2>\n<ul>\n<li>Did you enable a re-drive policy for your service's SQS Queues to reduce the number of messages and mitigate the effects of poison pill messages?\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/working-with-messages.html#capturing-problematic-messages\">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/working-with-messages.html#capturing-problematic-messages</a></li>\n</ul>\n</li>\n<li>Did you configure dead-letter queue to have a longer retention period than the original queue? The expiration of a message is always based on its original enqueue timestamp.\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/working-with-messages.html#setting-up-dead-letter-queue-retention\">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/working-with-messages.html#setting-up-dead-letter-queue-retention</a></li>\n</ul>\n</li>\n<li>Do you have alarms in place for metrics published by SQS?\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-available-cloudwatch-metrics.html\">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-available-cloudwatch-metrics.html</a></li>\n<li><a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/set-cloudwatch-alarms-for-metrics.html\">https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/set-cloudwatch-alarms-for-metrics.html</a></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"ecs\" style=\"position:relative;\"><a href=\"#ecs\" aria-label=\"ecs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ECS</h2>\n<ul>\n<li>Did you configure your containers in the tasks to send log information to CloudWatch?\n<ul>\n<li><a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definition_storage\">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definition_storage</a></li>\n<li><a href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html\">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/using_awslogs.html</a></li>\n</ul>\n</li>\n</ul>","frontmatter":{"date":"June 21, 2022","path":"/blogs/aspects-of-software-system-auditing-backend","tags":["blog","experience","microservice"],"title":"Aspects of Software System Auditing - Backend","description":"When we audit a backend service, what aspects should we look at?"}}},"pageContext":{"prev":{"frontmatter":{"path":"/blogs/backend-services-case-study","tags":["blog","case study","experience"],"password":null},"internal":{"content":"\n```toc\n```\n\n## Application 1 - A Web UI Application\n\n### Overview\nA UI application with Java Spring-based backend and JSP (migrating to React) frontend hosted on Tomcat server. Stateless application, using session Id tracked in cookies to retrieve/store session date from DynamoDB.\n\nThe application provides users a UI illustrating directed workflows to achieve business purposes. The frontend-backend interaction follows \"single API pattern\":\n![backend-frontend](images/backend-frontend.jpeg)\n\nThe frontend is simply a \"one-page application\". It receives a json telling it to \"put this text in the textbox with this id in the UI\". This json also enable/disable potential user input components in the UI by providing ID, for example scanner/button. Once user triggered any action, the action ID and it's value will be sent to the backend API.\n\nThe backend receives the request and will fetch session data from DB by the session id in the request. Session data is a list of \"serializable object\" storing the current states. Overall, the backend is a state machine, given the states from session DB, plus user action ID and value, it will compute the next \"step\" of states based on the defined state transition logic. Selected \"next step\" will be sent back to the frontend and will be used for rendering.\n\n### TPS/QPS\nThere are 3 main regions of this application.\n* Region 1: there are 24.5M of \"Unit-of-Work\" every day and 6.2% of them are processed by this app, about 1.5M/Day. TPS is 61(MAX, 1 min dp), 25(MIN, 1min dp) and 45(AVG, 1min dp)\n* Region 2: there are 10M of \"Unit-of-Work\" every day and 10% of them are processed by this app, about 1M/Day. TPS is 32(MAX, 1 min dp), 3(MIN, 1min dp) and 17(AVG, 1min dp)\n* Region 3: there are 2.2M of \"Unit-of-Work\" every day and 3% of them are processed by this app, about 67K/Day. TPS is 4(MAX, 1 min dp), ~0(MIN, 1min dp) and 1.3(AVG, 1min dp)\n\n### Latency (region 1, 1min dp)\n> \"AVG Stat\" means the datapoints are calculated as the avg of datapoints in 1 min\n* AVG Stat: 742ms; MAX: 1042ms; MIN: 583ms\n* p90 Stat: AVG: 1585ms\n* p99 Stat: AVG: 2786ms\n\n### Critical Dependencies (region 1)\n#### DynamoDB for Session Data\n* WCU(/s): Min: 14.175; Max: 75.46; Average: 51.204\n* RCU(/s): Min: 46.309; Max: 243.06; Average: 165.63\n* Latency: \n    * Get: 1.6ms\n    * Put: 3.5ms\n* Item count (with 12 hours TTL): 41K\n* Table size: 155 megabytes\n* Avg item size: 3780 bytes\n* Point-in-time recovery: Enabled\n* GSI/LSI: None\n\n### Billing (region 1)\n* EC2 usage: Unknown\n    * `21` m5-xlarge hosts\n    * CPU usage is around 10%\n* Session Data DynamoDB: $620/month, with provisioned RCU as 274 and WCU as 895\n* CloudWatch: $45,797.97/month (reason: unknown)\n* Lambda (used for one usecase in this app): \n    * Every 1 min, will be triggered once, 1460 invocations/day\n    * Duration is 20s in AVG\n    * $25/month\n* Another DynamoDB:\n    * Item Count: 105,720,519\n    * Table Size: 16.1 Gigabytes\n    * Average item size: 152.02 bytes\n    * WCU/s: ~50\n    * RCU/s: ~0\n    * Billing: $162/month\n\n## Application 2 - AWS-Heavy Application\n\n### Overview\nApplication 2 heavily depends on AWS services. Its clients push messages into SNS-SQS input buffer, then application 2 fetches messages from SQS and do aggregation on the message then push to different destination in AWS.\n\n### TPS/QPS and Latency (region 1)\n* API-1: \n    * TPS: AVG: 463; MAX: 750; MIN: 100;\n    * Latency: AVG: 180ms; p99: 355ms\n* API-2: TPS: AVG: 2; Latency: AVG: ~200ms;\n* API-3: TPS: AVG: 2; Latency: AVG: ~100ms;\n* API-4: TPS: AVG: 3; Latency: AVG: ~200ms;\n* API-5: TPS: AVG: 266; latency: AVG: 75ms;\n* API-6: TPS: AVG: 5; latency: AVG: ~500ms;\n\n### Critical Dependencies and Billing (region 1)\n* CloudWatch: 87 Dashboards: $267/month\n* Cognito: 183 users: $2.75/month\n* Data Tranfer\n    * Data transfer in per month: 5689.145GB: $0\n    * regional data transfer - in/out/between EC2 AZs or using elastic IPs or ELB: 3272.145GB: $32.72\n    * first 10TB/month data transfer out: 1024GB: $921\n    * next 40TB/month data transfer out: 19544.948GB: $1661.32\n* DynamoDB: 18.455GB data, 458 RCU/s, 2ZWCU/s\n    * 521,570.000 ReadCapacityUnit-Hrs: $67.8\n    * 26,040.000 WriteCapacityUnit-Hrs: $16.93\n    * 25GB free GB-Months free tier: $0\n    * PITR Storage: $3.52\n* Kinesis Firehose: 14,388.931 GB data ingested\n    * $417.28\n* OpenSearch Service: \n    * Data nodes: 36 nodes, m5.2xlarge.search, 1400GiB\n    * Master nodes: 3 nodes, m5.large.search\n    * Snapshot: hourly\n    * Billing: $22,250/month\n* Redshift:\n    * $0.250 per Redshift Dense Compute Large (DC2.L) Compute Node-hour (or partial hour)7,430.908 Hrs\n    * $1857.72/month\n* SNS: $1365/month\n    * Note: on average, one request will generate 2 SNS publishing\n* SQS: $2427.15\n    * Note: one request one message\n* S3: \n    * Amazon Simple Storage Service Requests-Tier1: 0.005 per 1,000 PUT, COPY, POST, or LIST requests1,052,492.000 Requests - $5.26\n    * Amazon Simple Storage Service Requests-Tier2: 0.004 per 10,000 GET and all other requests956,677.000 Requests - $0.38\n    * Storage: 85,875.333 GB-Mo - $1940.46/month\n* In total: $59011.99/month\n\n## Application 3 - DynamoDB Intensive Application\n### Overview\nThis application heavily depends on DynamoDB.\n\n### TPS/QPS and Latency (region 1)\n* API-1(GET): TPS: AVG: 511; Latency: AVG: 10.19ms; p99: 38ms\n* API-2(GET): TPS: AVG: ~1; Latency: AVG: 20ms; p99: 75ms\n* API-3(PUT): TPS: AVG: 348; Latency: AVG: 56ms; p99: 172ms\n\n### Billing (region 1)\n* Table 1:\n    * Item count: 22,413,875,643\n    * Table size: 14.5 TB\n    * Average item size: 647.13B\n    * RCU/s: 17248 (previsioned: 38,670)\n    * WCU/s: 2067 (prevision: 4550)\n    * Put latency: -\n    * Query Latency: 6ms\n* Table 2:\n    * Item count: 556,608,790\n    * Table size: 141.2 gigabytes\n    * Average item size: 253.72 bytes\n    * RCU/s: 944 (previsioned: 2225)\n    * WCU/s: 3.3 (prevision: 20)\n    * Put latency: -\n    * Get latency: ~1ms\n* Table 3:\n    * Item count: 849,617,771\n    * Table size: 565.1 gigabytes\n    * Average item size: 665.09 bytes\n    * RCU/s: 2074 (previsioned: 4693)\n    * WCU/s: 216 (prevision: 490)\n    * Put latency: -\n    * Get latency: 2ms\n* Total billing:\n    * $22,722.04\n* Additional:\n    * CloudWatch: $3,849"}},"next":{"frontmatter":{"path":"/blogs/password-protected-gatsby-blog","tags":["blog","idea","gatsby","backlog"],"password":null},"internal":{"content":"\n## Idea\n![idea](images/WeChatec11220bcea4925a002d645f78b3f876.png)\n\n## Proof of Concept\nType \"secret\" in the input box to decypher the blog.\n\nhttps://zzzgin.github.io/artworks/playground/encrypted-blog\n\n## Tasks Break Down\n1. Create a react component take an json obejct and render the markdown \n    1. inputs:\n        ``` json\n        {\n            \"path\": \"/private/a-blog-protected-by-password\",\n            \"date\": \"2022-06-20T02:32:17.078Z\",\n            \"title\": \"A Blog Protected By Password\",\n            \"description\": \"Some description\",\n            \"tags\": [\"private\"],\n            \"featuredimage\": \"url-of-image\",\n            \"featuredimageAlt\": \"alt\",\n            \"content\": \"encrypted content\"\n        }\n        ```\n    2. An `input` element to take the user cipher\n2. automation script to transfer markdown to the json, then transfer back.\n3. change in `gatsby-node` to create pages for private blogs\n4. merge tags"}}}},
    "staticQueryHashes": []}